{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Concensus_voting_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_K7ljUChUmi",
        "outputId": "d5ae97e3-172f-4ca8-c9fd-3917d6162b3b"
      },
      "source": [
        "! gdown https://drive.google.com/u/0/uc?id=17WpSslT1bv81vHy3k1u0lo53_S10evDe\n",
        "# For the train+val set\n",
        "! unzip -qq CXR_Covid-19_Challenge.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=17WpSslT1bv81vHy3k1u0lo53_S10evDe\n",
            "To: /content/CXR_Covid-19_Challenge.zip\n",
            "3.61GB [00:56, 63.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRDr5zNWhowr",
        "outputId": "8a589d4f-d427-4522-a707-2017c0efd602"
      },
      "source": [
        "# For the test data\n",
        "! gdown https://drive.google.com/u/0/uc?id=13S_GWX1f6K0ySqgeuQmH0pShhbTiT_EZ\n",
        "! unzip -qq test_set.zip\n",
        "\n",
        "! mkdir test_set\n",
        "! mv *.jpg test_set\n",
        "# ! mv *.png test_set # if png present in test set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=13S_GWX1f6K0ySqgeuQmH0pShhbTiT_EZ\n",
            "To: /content/test_set.zip\n",
            "181MB [00:01, 92.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntzm9Z3FiDx3"
      },
      "source": [
        "# Download all the models from Nilu's drive\n",
        "#! gdown https://drive.google.com/u/0/uc?id=1VZea7fcT7wNlNxiJPunNtBVJBmkjCRUl # DenseNet201\n",
        "#! gdown https://drive.google.com/u/0/uc?id=1t6DqQxwCB5Bwj_qlbzeImqqN2VXqzSDJ # InceptionResNetV2_train\n",
        "#! gdown https://drive.google.com/u/0/uc?id=1cr_S8WfCdl1Pmx5b8GEkCBxbTRBrQjK9 # Xception\n",
        "#! gdown https://drive.google.com/u/0/uc?id=1EgtqKPWP2XzXpGWc8fXz2V19sjT5ORVW # InceptionV3_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VldJ-Kn5kDRH",
        "outputId": "d1ebf8dd-be1a-4e1b-8547-b47a1a0fd63c"
      },
      "source": [
        "# From Jimut's drive\n",
        "! gdown https://drive.google.com/u/0/uc?id=1NJjRRV-kwxB381O-8Gr8e6MC4IZWeJV0 # VGG16-best\n",
        "! gdown https://drive.google.com/u/0/uc?id=1tmKkVBpJskNqFkQNh_CC4OTFRrzKG5Bg # InceptionV3_train\n",
        "! gdown https://drive.google.com/u/0/uc?id=1kBtJvSWPnNrqEhhH9hwlXFXMWXeT_CyP # Xception\n",
        "! gdown https://drive.google.com/u/0/uc?id=1GydERHlO1hKEzJhuA0MMlZ_xPKUAqSjG # InceptionResNetV2_train\n",
        "! gdown https://drive.google.com/u/0/uc?id=1ZoHCSw3RaRTgMEnuaTASeYxsKnT8UMH_ # DenseNetV2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1NJjRRV-kwxB381O-8Gr8e6MC4IZWeJV0\n",
            "To: /content/CXR_Covid-19_100e_VGG_16_all_500x500_1024_dropout-1024-3.h5\n",
            "196MB [00:02, 74.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1tmKkVBpJskNqFkQNh_CC4OTFRrzKG5Bg\n",
            "To: /content/CXR_Covid-19_100e_InceptionV3_500x500_1024-1024-3_val.h5\n",
            "301MB [00:02, 138MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1kBtJvSWPnNrqEhhH9hwlXFXMWXeT_CyP\n",
            "To: /content/CXR_Covid-19_50e_Xception_360x360_128-32-3.h5\n",
            "254MB [00:01, 131MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1GydERHlO1hKEzJhuA0MMlZ_xPKUAqSjG\n",
            "To: /content/CXR_Covid-19_50e_InceptionResNetV2_360x360_128-32-3_train.h5\n",
            "657MB [00:06, 99.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1ZoHCSw3RaRTgMEnuaTASeYxsKnT8UMH_\n",
            "To: /content/CXR_Covid-19_50e_DenseNet201_360x360_128-32-3.h5\n",
            "224MB [00:01, 120MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6PP2I3roIXU"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D,\\\n",
        "                                    GlobalMaxPool2D, Dropout, SpatialDropout2D, add, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall, SensitivityAtSpecificity, PrecisionAtRecall, \\\n",
        "                                     TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import keras\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import time\n",
        "import cv2\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya6MrMjFoeWT"
      },
      "source": [
        "# Indices\n",
        "index = {'normal': 0, 'covid': 1,  'pneumonia': 2}\n",
        "rev_index = {0: 'normal',1: 'covid', 2: 'pneumonia'}\n",
        "\n",
        "# For submission => 0:covid, 1: normal , 2: pneu\n",
        "sub_index = {1:0, 0:1, 2:2}\n",
        "# rev_sub_index = {0:1, 1:0, 2:2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2zvr_0Nmed0",
        "outputId": "653942e3-5307-4d9f-f08f-73a90a3efc6b"
      },
      "source": [
        "from keras import backend as K\n",
        "#from tensorflow import keras.applications.inception_resnet_v2\n",
        "\n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "model_incepV3 = keras.models.load_model('CXR_Covid-19_100e_InceptionV3_500x500_1024-1024-3_val.h5', custom_objects={'specificity': specificity, 'sensitivity': sensitivity})\n",
        "model_denseNet = keras.models.load_model('CXR_Covid-19_50e_DenseNet201_360x360_128-32-3.h5', custom_objects={'specificity': specificity, 'sensitivity': sensitivity})\n",
        "model_incepRNV2 = keras.models.load_model('CXR_Covid-19_50e_InceptionResNetV2_360x360_128-32-3_train.h5', custom_objects={'specificity': specificity, 'sensitivity': sensitivity})\n",
        "model_Xcep = keras.models.load_model('CXR_Covid-19_50e_Xception_360x360_128-32-3.h5', custom_objects={'specificity': specificity, 'sensitivity': sensitivity})\n",
        "model_VGG16 = keras.models.load_model('CXR_Covid-19_100e_VGG_16_all_500x500_1024_dropout-1024-3.h5', custom_objects={'specificity': specificity, 'sensitivity': sensitivity})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/layers/core.py:1045: UserWarning: tensorflow.python.keras.applications.inception_resnet_v2 is not loaded, but a Lambda layer uses it. It may cause errors.\n",
            "  , UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ECZHbXzpLIR",
        "outputId": "ad4d2a6d-1baf-46ae-8063-b446e77fdebb"
      },
      "source": [
        "##################################\n",
        "H, W, C = 360, 360, 3\n",
        "N_LABELS = len(index)\n",
        "D = 1\n",
        "##################################\n",
        "\n",
        "def parse_filepath(filepath):\n",
        "    try:\n",
        "        #path, filename = os.path.split(filepath)\n",
        "        label = filepath.split('/')[1]\n",
        "        #filename, ext = os.path.splitext(filename)\n",
        "        #label, _ = filename.split(\"_\")\n",
        "        return label\n",
        "    except Exception as e:\n",
        "        print('error to parse %s. %s' % (filepath, e))\n",
        "        return None, None\n",
        "\n",
        "files_validation = glob.glob(\"validation/*/*.*\")\n",
        "print(\"Total files valid = \",len(files_validation))\n",
        "\n",
        "# create a pandas data frame of images, age, gender and race\n",
        "attributes = list(map(parse_filepath, files_validation))\n",
        "\n",
        "df_val = pd.DataFrame(attributes)\n",
        "df_val['file'] = files_validation\n",
        "df_val.columns = ['label', 'file']\n",
        "df_val = df_val.dropna()\n",
        "df_val.tail()\n",
        "\n",
        "print(len(df_val))\n",
        "p = np.random.permutation(len(df_val))\n",
        "test_idx = p[:len(df_val)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files valid =  3432\n",
            "3432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiwjdlspoaiL"
      },
      "source": [
        "# Test on the train/val set to be sure...\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "\n",
        "def get_data_generator(df, indices, for_training, batch_size=16):\n",
        "    images, labels = [], []\n",
        "    while True:\n",
        "        # print(\"indices = \",indices)    \n",
        "        # print(\"len indices = \",len(indices))\n",
        "        for i in indices:\n",
        "            r = df.iloc[i]\n",
        "            # print(\" r = \", r, \" i = \",i)\n",
        "            file, label = r['file'], r['label']\n",
        "            # print(\"file, label = \",file, label)\n",
        "            im_gray = Image.open(file).convert('L')\n",
        "            # print(\"Shape = \",im_gray.shape)\n",
        "            im_gray = im_gray.resize((360, 360))\n",
        "            im = np.zeros(shape=(360, 360,3))\n",
        "            \n",
        "            im[:,:,0] = im_gray\n",
        "            im[:,:,1] = im_gray\n",
        "            im[:,:,2] = im_gray\n",
        "            im = np.array(im) / 255.0\n",
        "\n",
        "            # print(im.shape)\n",
        "            images.append(im)\n",
        "            # print(np.asarray([to_categorical(index[label], N_LABELS)]))\n",
        "            # print(np.asarray([to_categorical(index[label], N_LABELS)]).shape)\n",
        "            \n",
        "            labels.append(to_categorical(index[label], N_LABELS))\n",
        "            if len(images) >= batch_size:\n",
        "                yield np.array(images), np.array(labels)\n",
        "                images, labels = [], []\n",
        "        # if not for_training:\n",
        "        #     break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "YP2BmVJhpqTz",
        "outputId": "488a3505-91fc-481c-83b0-e8510761b207"
      },
      "source": [
        "test_gen = get_data_generator(df_val, test_idx, for_training=False)\n",
        "dict(zip(model_Xcep.metrics_names, model_Xcep.evaluate(test_gen, steps=len(test_idx))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  47/3432 [..............................] - ETA: 23:52 - loss: 0.3794 - accuracy: 0.9481 - sensitivity: 0.9481 - specificity: 0.9741"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f3b3e1b7ae3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_Xcep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_Xcep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5JZkK7GqQkA",
        "outputId": "7c112048-7efa-47cf-83e1-6a220c669ec6"
      },
      "source": [
        "test_files = glob.glob('test_set/*.jpg')\n",
        "print(len(test_files))\n",
        "test_files = sorted(test_files)\n",
        "test_files[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_set/0001.jpg',\n",
              " 'test_set/0002.jpg',\n",
              " 'test_set/0003.jpg',\n",
              " 'test_set/0004.jpg',\n",
              " 'test_set/0005.jpg',\n",
              " 'test_set/0006.jpg',\n",
              " 'test_set/0007.jpg',\n",
              " 'test_set/0008.jpg',\n",
              " 'test_set/0009.jpg',\n",
              " 'test_set/0010.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu0HN84BqdHW",
        "outputId": "8ea26839-adaf-4654-cd17-f0f5b7ba4b20"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "# y_pred_list = []\n",
        "# y_test_list = []\n",
        "\n",
        "sub_dic = {}\n",
        "i=1\n",
        "\n",
        "for file_path in tqdm(test_files):\n",
        "    file_name = file_path.split('/')[1]\n",
        "    # print(file_name)\n",
        "    # break\n",
        "\n",
        "    im_gray = Image.open(file_path).convert('L')\n",
        "    im_gray_360 = im_gray.resize((360, 360))\n",
        "    im_gray_500 = im_gray.resize((500, 500))\n",
        "    im_360 = np.zeros(shape=(360, 360, 3))\n",
        "    im_500 = np.zeros(shape=(500, 500, 3))\n",
        "\n",
        "    im_360[:,:,0] = im_gray_360\n",
        "    im_360[:,:,1] = im_gray_360\n",
        "    im_360[:,:,2] = im_gray_360\n",
        "\n",
        "    im_500[:,:,0] = im_gray_500\n",
        "    im_500[:,:,1] = im_gray_500\n",
        "    im_500[:,:,2] = im_gray_500\n",
        "\n",
        "    im_360 = np.array(im_360) / 255.0\n",
        "\n",
        "    im_500 = np.array(im_500) / 255.0\n",
        "\n",
        "    y_pred_incepV3 = model_incepV3.predict(im_500[np.newaxis, ...])\n",
        "    y_pred_denseNet = model_denseNet.predict(im_360[np.newaxis, ...])\n",
        "    y_pred_incepRNV2 = model_incepRNV2.predict(im_360[np.newaxis, ...])\n",
        "    y_pred_Xcep = model_Xcep.predict(im_360[np.newaxis, ...])\n",
        "    y_pred_VGG = model_VGG16.predict(im_500[np.newaxis, ...])\n",
        "\n",
        "    pred_incepV3 = sub_index[int(tf.math.argmax(y_pred_incepV3, axis=-1))]\n",
        "    pred_denseNet = sub_index[int(tf.math.argmax(y_pred_denseNet, axis=-1))]\n",
        "    pred_incepRNV2 = sub_index[int(tf.math.argmax(y_pred_incepRNV2, axis=-1))]\n",
        "    pred_Xcep = sub_index[int(tf.math.argmax(y_pred_Xcep, axis=-1))]\n",
        "    pred_VGG = sub_index[int(tf.math.argmax(y_pred_VGG, axis=-1))]\n",
        "\n",
        "    '''\n",
        "    print(pred_incepV3, \"V3\")\n",
        "    print(pred_denseNet, \"DN\")\n",
        "    print(pred_incepRNV2, \"RNV2\")\n",
        "    print(pred_Xcep, \"XCP\")\n",
        "    '''\n",
        "\n",
        "    pred_dict = {0:0 , 1:0, 2:0}\n",
        "    pred_dict[pred_incepV3] += 1\n",
        "    pred_dict[pred_denseNet] +=1\n",
        "    pred_dict[pred_incepRNV2] +=1\n",
        "    pred_dict[pred_Xcep] +=1\n",
        "    pred_dict[pred_VGG] +=1\n",
        "    \n",
        "    rev_pred_dict = {}\n",
        "    for item in pred_dict:\n",
        "      rev_pred_dict[item] = pred_dict[item]\n",
        "    sub_dic[file_name] = max(pred_dict, key=pred_dict.get)\n",
        "    '''\n",
        "    i += 1\n",
        "    if i==5:\n",
        "      break\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 4825 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcb818899e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 4826 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcb834b4a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 1081/1200 [11:23<01:14,  1.60it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC6GKO06txkE",
        "outputId": "1888556d-dffa-4242-d33d-db73f5ef1599"
      },
      "source": [
        "sub_dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0001.jpg': 2, '0002.jpg': 2, '0003.jpg': 1, '0004.jpg': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awHiyVd8qgbg"
      },
      "source": [
        "import csv\n",
        "toCSV = []\n",
        "\n",
        "for item in sub_dic:\n",
        "    # print(item, \" , \",sub_dic[item])\n",
        "    toCSV.append({'case': item, 'class':sub_dic[item]})\n",
        "\n",
        "keys = toCSV[0].keys()\n",
        "\n",
        "with open('submission.csv', 'w', newline='')  as output_file:\n",
        "    dict_writer = csv.DictWriter(output_file, keys)\n",
        "    dict_writer.writeheader()\n",
        "    dict_writer.writerows(toCSV)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}