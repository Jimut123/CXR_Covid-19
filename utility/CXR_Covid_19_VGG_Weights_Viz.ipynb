{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CXR_Covid_19_VGG_Weights_Viz.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuiU2YnXi2bA",
        "outputId": "a53387cc-aa16-40aa-b634-16970240d8a3"
      },
      "source": [
        "! gdown https://drive.google.com/u/0/uc?id=17WpSslT1bv81vHy3k1u0lo53_S10evDe"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=17WpSslT1bv81vHy3k1u0lo53_S10evDe\n",
            "To: /content/CXR_Covid-19_Challenge.zip\n",
            "3.61GB [00:56, 64.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EeZgaQDi5L1"
      },
      "source": [
        "! unzip -qq CXR_Covid-19_Challenge.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svP71MPdExwM"
      },
      "source": [
        "# ! gdown https://drive.google.com/u/2/uc?id=1cpqqgbb77-1vt5-SvmQWV2Klla_tuLjD"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7gsSHlQjJJO"
      },
      "source": [
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "###########################\n",
        "EPOCHS = 10\n",
        "MODEL_NAME = 'VGG_16'\n",
        "IMG_SIZE = '360x360'\n",
        "OUTPUT_LAYERS = '128-32-3'\n",
        "###########################"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl6nL0E0oI5P"
      },
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D,\\\n",
        "                                    GlobalMaxPool2D, Dropout, SpatialDropout2D, add, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall, SensitivityAtSpecificity, PrecisionAtRecall, \\\n",
        "                                     TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import keras\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1mN6sj9rCNR",
        "outputId": "b918c881-7211-43a4-9d5a-133322c29b20"
      },
      "source": [
        "N_LABELS = 3\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "# Change the pretrained model name according to the given criteria\n",
        "\n",
        "frozen = VGG16 (weights=\"imagenet\", input_shape=(360,360,3), include_top=False)\n",
        "frozen.summary()\n",
        "\n",
        "trainable = frozen.output\n",
        "trainable = GlobalAveragePooling2D()(trainable)\n",
        "#print(trainable.shape)\n",
        "trainable = Dense(128, activation=\"relu\")(trainable)\n",
        "trainable = Dense(32, activation=\"relu\")(trainable)\n",
        "trainable = Dense(N_LABELS, activation=\"softmax\")(trainable)\n",
        "model = Model(inputs=frozen.input, outputs=trainable)\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 360, 360, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 360, 360, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 360, 360, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 180, 180, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 180, 180, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 180, 180, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 90, 90, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 90, 90, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 90, 90, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 90, 90, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 45, 45, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 45, 45, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 45, 45, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 45, 45, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 22, 22, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 11, 11, 512)       0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 360, 360, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 360, 360, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 360, 360, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 180, 180, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 180, 180, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 180, 180, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 90, 90, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 90, 90, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 90, 90, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 90, 90, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 45, 45, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 45, 45, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 45, 45, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 45, 45, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 22, 22, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 11, 11, 512)       0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 14,784,579\n",
            "Trainable params: 14,784,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSBrFnTErCMB"
      },
      "source": [
        "# https://stackoverflow.com/questions/55640149/error-in-keras-when-i-want-to-calculate-the-sensitivity-and-specificity\n",
        "# add specificity and sensitivity here\n",
        "# https://datascience.stackexchange.com/questions/33587/keras-custom-loss-function-as-true-negatives-by-true-negatives-plus-false-posit/40746#40746\n",
        "# add some loss functions here\n",
        "\n",
        "# Metrics\n",
        "# https://www.sabinasz.net/unbalanced-classes-machine-learning/\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())\n",
        "\n",
        "\n",
        "\n",
        "opt = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
        "            experimental_run_tf_function=False,\n",
        "            metrics = ['accuracy', sensitivity, specificity]\n",
        "            )\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzce9yA-zUuD",
        "outputId": "d1db436f-9177-4eef-fb78-21f5970cc450"
      },
      "source": [
        "# ! gdown https://drive.google.com/u/2/uc?id=1Ma8-7fG8-CneFcR0qBJ2aXNakKXyujqS\n",
        "! gdown https://drive.google.com/u/0/uc?id=1_fWrH3qvkYhA8Y0j7DRMEf_xroE8WJBh"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1_fWrH3qvkYhA8Y0j7DRMEf_xroE8WJBh\n",
            "To: /content/CXR_Covid-19_100e_VGG_16_360x360_128-32-3.h5\n",
            "178MB [00:02, 84.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h15DmWHVE5cH"
      },
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model('CXR_Covid-19_100e_VGG_16_360x360_128-32-3.h5', custom_objects={'specificity': specificity, 'sensitivity': sensitivity})"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpbU7Lx80NyP",
        "outputId": "624b9bfb-01e6-4cdc-d1ed-a0f8cb737ad9"
      },
      "source": [
        "layer_names = []\n",
        "filter_depth = []\n",
        "for layer in model.layers:\n",
        "  if 'conv' not in layer.name:\n",
        "    continue\n",
        "  filters, biases = layer.get_weights()\n",
        "  print(layer.name, filters.shape)\n",
        "  layer_names.append(layer.name)\n",
        "  filter_depth.append(filters.shape[3])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "block1_conv1 (3, 3, 3, 64)\n",
            "block1_conv2 (3, 3, 64, 64)\n",
            "block2_conv1 (3, 3, 64, 128)\n",
            "block2_conv2 (3, 3, 128, 128)\n",
            "block3_conv1 (3, 3, 128, 256)\n",
            "block3_conv2 (3, 3, 256, 256)\n",
            "block3_conv3 (3, 3, 256, 256)\n",
            "block4_conv1 (3, 3, 256, 512)\n",
            "block4_conv2 (3, 3, 512, 512)\n",
            "block4_conv3 (3, 3, 512, 512)\n",
            "block5_conv1 (3, 3, 512, 512)\n",
            "block5_conv2 (3, 3, 512, 512)\n",
            "block5_conv3 (3, 3, 512, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmkevaBU0NSR"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHHgPeYN0HbP"
      },
      "source": [
        "# https://www.kaggle.com/anktplwl91/visualizing-what-your-convnet-learns\n",
        "\n",
        "# The purpose of this function is to just convert a numpy array to a standard image format, so that it can be displayed and viewed comfortably\n",
        "def deprocess_image(x):\n",
        "    \n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "    x *= 255\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "\n",
        "    return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEl5Q7frQkRT"
      },
      "source": [
        "# This function is used to create a loss function that maximizes the value of a given filter in a convolution layer, and then we use SGD to adjust the values of the\n",
        "# input image so as to maximize this activation value. We pass the layer name and the filter index to the function as arguments. 'loss' is the mean for that particular\n",
        "# filter, 'grads' is the gradient calculated for this loss with respect to input image. Finally, SGD is run for 80 iterations which continuously maximizes the response\n",
        "# to input image by adding the gradient. Finally, it uses 'deprocess_image' to convert this array to a representable image format.\n",
        "\n",
        "def generate_pattern(layer_name, filter_index, size=150):\n",
        "    \n",
        "    layer_output = model.get_layer(layer_name).output\n",
        "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "    grads = K.gradients(loss, model.input)[0]\n",
        "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "    iterate = K.function([model.input], [loss, grads])\n",
        "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
        "    step = 1.\n",
        "    for i in range(80):\n",
        "        loss_value, grads_value = iterate([input_img_data])\n",
        "        input_img_data += grads_value * step\n",
        "        \n",
        "    img = input_img_data[0]\n",
        "    return deprocess_image(img)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ARVGdGaQkOz",
        "outputId": "417c8818-4f69-4037-d566-8034d43584c1"
      },
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "\n",
        "# Below are the patterns to which the filters from first convolution layer get activated. As we can see these are very basic cross-sectional patterns formed by\n",
        "# horizontal and vertical lines, which is what the these filters look in the input image and get activated if they find one.\n",
        "\n",
        "c = 0\n",
        "for ln, fd in zip(layer_names,filter_depth):\n",
        "  \n",
        "  c += 1\n",
        "  if c<4:\n",
        "      continue\n",
        "  print(ln)\n",
        "  size = int(fd/16)\n",
        "  fig = plt.figure(figsize=(16, size))\n",
        "  for img in tqdm(range(fd)):\n",
        "      ax = fig.add_subplot(size, 16, img+1)\n",
        "      ax = plt.imshow(generate_pattern(ln, img))\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      fig.subplots_adjust(wspace=0.05, hspace=0.05)\n",
        "  plt.savefig(str(ln+\".png\"),bbox_inches='tight',pad_inches=0,dpi=300)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "block2_conv2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/128 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W5r8V4XQkMD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIPqHPabQkJY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CytU9bikQkG_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87GvUVTRQkDp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD1bS4ZWQkA-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fX3VMwFn5uV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2japjw-7n5sr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}